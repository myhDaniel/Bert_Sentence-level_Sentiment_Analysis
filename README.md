# Bert_Sentence-level_Sentiment_Analysis
BERT has become enormously popular and has proven to be effective in utilizing large-scale unlabled training data and generating enriched contextual representations. To evaluate the performance of BERT in sentence-level sentiment analysis, this project finetunes pretrained BERT based on Chinese with initial weights downloaded from the official source, and achieves an accuracy of 91.8% on the test set. 

The pretrained weights are available at the following link. 

Link：[https://pan.baidu.com/s/1JshJiDuSK938UIQ2CKhlig](https://pan.baidu.com/s/1JshJiDuSK938UIQ2CKhlig) 

Extract code：1234

Notice: The weight files should be stored in the same directory as the code file.
